{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "535481d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initial preprocessing \n",
    "# 1. lang dtection \n",
    "# 2. lang translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "536a06aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing libraries \n",
    "import pandas as pd \n",
    "from langdetect import detect\n",
    "from googletrans import Translator\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from wordcloud import WordCloud\n",
    "from nltk.util import ngrams\n",
    "from rake_nltk import Rake\n",
    "import yake \n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "import contractions\n",
    "from string import punctuation\n",
    "from unidecode import unidecode\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7d0eb74e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_title</th>\n",
       "      <th>language</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>es_0491108</td>\n",
       "      <td>product_es_0296024</td>\n",
       "      <td>reviewer_es_0999081</td>\n",
       "      <td>1</td>\n",
       "      <td>Nada bueno se me fue ka pantalla en menos de 8...</td>\n",
       "      <td>television Nevir</td>\n",
       "      <td>es</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>es_0869872</td>\n",
       "      <td>product_es_0922286</td>\n",
       "      <td>reviewer_es_0216771</td>\n",
       "      <td>1</td>\n",
       "      <td>Horrible, nos tuvimos que comprar otro porque ...</td>\n",
       "      <td>Dinero tirado a la basura con esta compra</td>\n",
       "      <td>es</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_id          product_id          reviewer_id  stars  \\\n",
       "0  es_0491108  product_es_0296024  reviewer_es_0999081      1   \n",
       "1  es_0869872  product_es_0922286  reviewer_es_0216771      1   \n",
       "\n",
       "                                         review_body  \\\n",
       "0  Nada bueno se me fue ka pantalla en menos de 8...   \n",
       "1  Horrible, nos tuvimos que comprar otro porque ...   \n",
       "\n",
       "                                review_title language product_category  \n",
       "0                           television Nevir       es      electronics  \n",
       "1  Dinero tirado a la basura con esta compra       es      electronics  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"dataset_es_train.csv\")\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8d6ffdd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "\n",
    "final_data = data.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "887fa6b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_data = final_data[['review_body','stars']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e871a707",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3bab2f91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Es pequeña para mi MacBook Pro de 13, y me man...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lo devolví no tiene 1,5 cm de espesor el que m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llegaron con mucho retraso. No son de buena ca...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Es lo que dice y me gusta especialmente que so...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>es un elemento simple, de buena calidad de aca...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Me gusta la funcionalidad y su resistencia, bu...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Esta bien aunque tiene poca variedad de textur...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>No consigo conectarla con la aplicacion. He pr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Pequeño , la talla es muy pequeña , pedimos la...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Por el precio no está mal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           review_body  stars\n",
       "0    Es pequeña para mi MacBook Pro de 13, y me man...      1\n",
       "1    Lo devolví no tiene 1,5 cm de espesor el que m...      1\n",
       "2    Llegaron con mucho retraso. No son de buena ca...      2\n",
       "3    Es lo que dice y me gusta especialmente que so...      5\n",
       "4    es un elemento simple, de buena calidad de aca...      5\n",
       "..                                                 ...    ...\n",
       "995  Me gusta la funcionalidad y su resistencia, bu...      4\n",
       "996  Esta bien aunque tiene poca variedad de textur...      2\n",
       "997  No consigo conectarla con la aplicacion. He pr...      1\n",
       "998  Pequeño , la talla es muy pequeña , pedimos la...      1\n",
       "999                          Por el precio no está mal      3\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ec26229a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_body    object\n",
       "stars           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d1ec208b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lang_detection(data):\n",
    "    lang = detect(data)\n",
    "    return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "09d90028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_data['language'] = final_data['review_body'].apply(lang_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f91e4f50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "es    974\n",
       "pt     13\n",
       "en      7\n",
       "ca      3\n",
       "so      2\n",
       "de      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data['language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9b5a8d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # lang translation \n",
    "# def lang_translation(data):\n",
    "#     translator = Translator()\n",
    "#     clean_text = translator.translate(data)\n",
    "#     return clean_text.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0eae41dc-70d0-4d5d-abcc-a3b6b4583b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from translate import Translator\n",
    "\n",
    "def lang_translation(text, src_lang='es', dest_lang='en'):\n",
    "    \"\"\"\n",
    "    Translates a given text to English using an offline translation model.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The text to be translated.\n",
    "        src_lang (str): The source language code (e.g., 'es' for Spanish).\n",
    "        dest_lang (str): The destination language code (e.g., 'en' for English).\n",
    "\n",
    "    Returns:\n",
    "        str: The translated text in English.\n",
    "    \"\"\"\n",
    "    translator = Translator(from_lang=src_lang, to_lang=dest_lang)\n",
    "    translated_text = translator.translate(text)\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "01bee6ac-32a0-4b08-9ec3-3720ea770e13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Es pequeña para mi MacBook Pro de 13, y me mandaron otro dibujo, lo raro es que si busco por el código de barras me devuelve el que yo pedí, por lo que estimo que está mal etiquetada. La pediré de nuevo a ver si la mandan bien. Llegó a tiempo, como siempre.'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data['review_body'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fb554cd4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It is small for my MacBook Pro of 13, and they sent me another drawing, the strange thing is that if I look for the barcode it returns the one I ordered, so I think it is mislabeled. I'll ask her again to see if they send her well. He arrived on time, as always.\""
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_translation(final_data['review_body'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96af92b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El cable es muy largo y es comodo pero me duró poco tiempo porque el conector microusb se me acabó doblando'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data['review_body'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263b966d-7693-4b8d-baa6-2cdf175011a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_translation(final_data['review_body'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70d9b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_data['translated_review'] = final_data['review_body'].apply(lang_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c265db32",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf24f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordlist =  stopwords.words(\"english\")\n",
    "stopwordlist.remove('not')\n",
    "stopwordlist.remove('nor')\n",
    "stopwordlist.remove('no')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "649874a6-a804-4a72-874f-203b29009639",
   "metadata": {},
   "source": [
    "i did not like the movie  : like movie\n",
    "i like the movie : like movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0805e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ngrams(data,ngram_range):\n",
    "    tokens = [word.lower() for word in word_tokenize(data) if (word not in punctuation) and (word.isalpha()) and (word.lower() not in stopwordlist)]\n",
    "    ngrams_list = ngrams(tokens,ngram_range)\n",
    "    final_ngrams = []\n",
    "    for words in ngrams_list:\n",
    "        final_ngrams.append(\" \".join(words))\n",
    "    return final_ngrams\n",
    "\n",
    "unigram_list = final_data.translated_review.apply(lambda x :extract_ngrams(x,1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cf98df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_unigram = []\n",
    "for unigram in unigram_list:\n",
    "    final_unigram.extend(unigram)\n",
    "top_25_unigrams = Counter(final_unigram).most_common(100)\n",
    "top_25_unigrams"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4eeeabf-a39f-4d75-aba2-60623c78f480",
   "metadata": {},
   "source": [
    "unigrams ->  gives most frequent words, gives understanding of domain specific stopwords. Have to use common sense. Domain expertise can help with domain specific stopwords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7407e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordcloud  : \"\"\n",
    "def generate_wordcloud(data,column):\n",
    "    df = data[column].str.cat(sep=\" \") # record1   record 2 \n",
    "    text = \" \".join([word for word in df.split()])# \n",
    "    word_cloud = WordCloud(height=500,width=700,background_color='white',min_font_size=10).generate(text)\n",
    "    plt.figure(figsize=(10,16))\n",
    "    plt.imshow(word_cloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103f128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_wordcloud(final_data,'translated_review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9895689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. remove blanklines,whitespaces,tabs \n",
    "def remove_spaces(data):\n",
    "    \"Function will remove all spaces\"\n",
    "    formatted_text = data.replace('\\\\n',' ').replace('\\t',' ').replace(\"\\\\\",' ')\n",
    "    return formatted_text \n",
    "# 2. Contraction mapping \n",
    "def expand_text(data):\n",
    "    fixed_text = contractions.fix(data)\n",
    "    return fixed_text\n",
    "\n",
    "# 3. Handling accented \n",
    "def handling_accented(data):\n",
    "    fixed_text = unidecode(data)\n",
    "    return fixed_text\n",
    "# 4.cleaning \n",
    "stopword_list = stopwords.words(\"english\")\n",
    "stopword_list.remove(\"not\")\n",
    "stopword_list.remove(\"nor\")\n",
    "stopword_list.remove(\"no\")\n",
    "def cleaning(data):\n",
    "    tokens = word_tokenize(data) # tokenization\n",
    "    clean_text = [word.lower() for word in tokens if (word not in stopword_list) and(word not in punctuation) and(len(word)>2) and(word.isalpha())]\n",
    "    return clean_text\n",
    "\n",
    "# 5. autocorrect \n",
    "def autocorrection(data):\n",
    "    spell = Speller(lang='en')\n",
    "    corrected_text = spell(data)\n",
    "    return corrected_text\n",
    "\n",
    "# 6. Lemmatization \n",
    "def lemmatization(data):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    final_text = []\n",
    "    for word in data:\n",
    "        lemmatized_word = lemmatizer.lemmatize(word)\n",
    "        final_text.append(lemmatized_word)\n",
    "    return \" \".join(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de95042",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = final_data.translated_review.apply(remove_spaces)\n",
    "clean_text = clean_text.apply(expand_text)\n",
    "clean_text = clean_text.apply(handling_accented)\n",
    "clean_text = clean_text.apply(cleaning)\n",
    "clean_text = clean_text.apply(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43056dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization \n",
    "# 1. Count vectorizer \n",
    "count_vec = CountVectorizer()\n",
    "bow = count_vec.fit_transform(clean_text).A\n",
    "pd.DataFrame(bow,columns=count_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfd2880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Tfidf vectorizer \n",
    "tfidf_vec = TfidfVectorizer()\n",
    "tfidf_val = tfidf_vec.fit_transform(clean_text).A\n",
    "pd.DataFrame(tfidf_val,columns=tfidf_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c01a9d6-63f1-4446-9e9c-1a20b898c484",
   "metadata": {},
   "source": [
    "**The silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation).\n",
    "The silhouette ranges from −1 to +1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters.**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ca55244-67d2-4982-b6b3-ee890e4c9098",
   "metadata": {},
   "source": [
    "silhouette score  = b-a / max(a,b)\n",
    "\n",
    "a = intra distance : this is distance between points within cluster \n",
    "b = inter distance : distance between cluster \n",
    "    \n",
    "-1  : clusters are not properly build\n",
    "    \n",
    "+1  : clusters are build properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf8b33d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [[w1,w2],[]]\n",
    "sent = clean_text.tolist()\n",
    "final_text = [sen.split() for sen in sent]  # [[],[]]\n",
    "final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bded7292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec \n",
    "word2vec_model = Word2Vec(final_text,min_count=2,window=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e783d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model \n",
    "word2vec_model.save(\"Word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cc34ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.wv : vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec55f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc vect = vect1+ vect2/2\n",
    "def vectorizer(list_docs,model):\n",
    "    feature = [] # we will save vector of a document \n",
    "    for doc in list_docs : # iterate over all the reviews \n",
    "        zero_vector = np.zeros(model.vector_size) #  zero vector for handling key error\n",
    "        vectors = []\n",
    "        for word in doc :\n",
    "            if word in model.wv : # it just checks if word is present or not in models vocabulary\n",
    "                try : \n",
    "                    vectors.append(model.wv[word])\n",
    "                except KeyError :\n",
    "                    continue\n",
    "        if vectors :\n",
    "            vectors = np.asarray(vectors)\n",
    "            avg_vec = vectors.mean(axis=0)\n",
    "            feature.append(avg_vec)\n",
    "        else :\n",
    "            feature.append(zero_vector)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c4fb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_docs = vectorizer(final_text,word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708a5212",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_emb = np.array(vectorized_docs)\n",
    "x_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e742bb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans \n",
    "def build_kmeans(clusters,data):\n",
    "    kmeans_model = KMeans(n_clusters=clusters)\n",
    "    y_pred = kmeans_model.fit_predict(data)\n",
    "    return kmeans_model,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bc1581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans- count \n",
    "bow_kmeans_model,bow_pred = build_kmeans(3,bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d842ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans-tfidf \n",
    "tfidf_kmeans_model,tfidf_pred = build_kmeans(3,tfidf_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb03d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans-word2vec\n",
    "word2vec_kmeans_model,word2vec_pred = build_kmeans(3,x_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fbc7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation with silhouette \n",
    "print(f\"silhouette score with KMeans- count {silhouette_score(bow,bow_pred)}\")\n",
    "print(f\"silhouette score with KMeans- tfidf  {silhouette_score(tfidf_val,tfidf_pred)}\")\n",
    "print(f\"silhouette score with KMeans- word2vec {silhouette_score(x_emb,word2vec_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6a48d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# silhouette visualizeer \n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "\n",
    "def visualize_silhouette(data,model,title):\n",
    "    visualizer = SilhouetteVisualizer(model,colors='yellowbrick')\n",
    "    visualizer.fit(data)\n",
    "    plt.title(f\"Silhouette visualizer with {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8220e3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans count \n",
    "visualize_silhouette(bow,bow_kmeans_model,\"kmeans-count\")   # all our clusters should be on positive. red line is centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90253980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf\n",
    "visualize_silhouette(tfidf_val,tfidf_kmeans_model,\"kmeans-tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b58c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec\n",
    "visualize_silhouette(x_emb,word2vec_kmeans_model,\"kmeans-word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a71b80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# target column\n",
    "word2vec_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eddade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root cause analysis\n",
    "final_data.translated_review[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac38b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rake \n",
    "from rake_nltk import Rake\n",
    "rake_extractor = Rake()\n",
    "rake_extractor.extract_keywords_from_text(final_data.translated_review[0])\n",
    "keyphrases = rake_extractor.get_ranked_phrases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4304ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.translated_review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca8c719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee9d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_extractor = yake.KeywordExtractor()\n",
    "keywords = kw_extractor.extract_keywords(final_data.translated_review[0])\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326c64d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_keyphrase = [kw[0] for kw in keywords[:4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917ef324",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_keyphrase = [sen.split() for sen in list_keyphrase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8ad274",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_keyphrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ce8aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc vect = vect1+ vect2/2\n",
    "def vectorizer(list_docs,model):\n",
    "    feature = [] # we will save vector of a document \n",
    "    for doc in list_docs : # iterate over all the reviews \n",
    "        zero_vector = np.zeros(model.vector_size) #  zero vector for handling key error\n",
    "        vectors = []\n",
    "        for word in doc :\n",
    "            if word in model.wv : # it just checks if word is present or not in models vocabulary\n",
    "                try : \n",
    "                    vectors.append(model.wv[word])\n",
    "                except KeyError :\n",
    "                    continue\n",
    "        if vectors :\n",
    "            vectors = np.asarray(vectors)\n",
    "            avg_vec = vectors.mean(axis=0)\n",
    "            feature.append(avg_vec)\n",
    "        else :\n",
    "            feature.append(zero_vector)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d92d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyphrase_vectors = vectorizer(list_keyphrase,word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ca4226",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect1 = keyphrase_vectors[0]\n",
    "vect2 = keyphrase_vectors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b387db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyphrase_list = [kw[0] for kw in keywords[:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254364a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyphrase_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169944bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# cosine_score = (np.dot(vect1,vect2))/(norm(vect1)*norm(vect2))\n",
    "dict1 = {}\n",
    "\n",
    "for index,kw1 in enumerate(keyphrase_list) : # iterate over keyphrases\n",
    "\n",
    "    for kw2 in keyphrase_list: # iterate over keyphrases\n",
    "    \n",
    "        list_keyphrase = list((kw1.split(),kw2.split())) # [[],[]]\n",
    "        keyphrase_vectors = vectorizer(list_keyphrase,word2vec_model) # vectors extraction of  keyphrases\n",
    "        vect1 = keyphrase_vectors[0]\n",
    "        vect2 = keyphrase_vectors[1]\n",
    "        cosine_score = (np.dot(vect1,vect2))/(norm(vect1)*norm(vect2)) # cosine similarity between each and every keyphrase\n",
    "        if cosine_score>0.85 : \n",
    "            dict1[index] = [kw1,kw2]\n",
    "            print(dict1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48113518",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f80f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'delete' : ['stop deleting', 'deleting the data']} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2302059",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
